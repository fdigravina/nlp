=== Embedding Model: distiluse-base-multilingual-cased-v1 ===
KNN: Accuracy = 0.36
LogisticRegression: Accuracy = 0.49
SVM: Accuracy = 0.5
RandomForest: Accuracy = 0.47
MLP: Accuracy = 0.47

=== Embedding Model: paraphrase-multilingual-MiniLM-L12-v2 ===
KNN: Accuracy = 0.38
LogisticRegression: Accuracy = 0.5
SVM: Accuracy = 0.47
RandomForest: Accuracy = 0.46
MLP: Accuracy = 0.46

=== Embedding Model: LaBSE ===
KNN: Accuracy = 0.5
LogisticRegression: Accuracy = 0.56
SVM: Accuracy = 0.56
RandomForest: Accuracy = 0.53
MLP: Accuracy = 0.47

=== Embedding Model: all-MiniLM-L6-v2 ===
KNN: Accuracy = 0.27
LogisticRegression: Accuracy = 0.44
SVM: Accuracy = 0.42
RandomForest: Accuracy = 0.34
MLP: Accuracy = 0.43







=== Embedding Model: LaBSE ===
KNN: Accuracy = 0.51
LogisticRegression: Accuracy = 0.56
SVM: Accuracy = 0.56
RandomForest: Accuracy = 0.56
MLP: Accuracy = 0.49

Best params KNN: {'algorithm': 'auto', 'n_neighbors': 10, 'p': 2, 'weights': 'distance'}
Best params LR: {'C': 10, 'max_iter': 200000, 'solver': 'newton-cholesky'}
Best params SVM: {'C': 1, 'loss': 'squared_hinge', 'max_iter': 500000, 'multi_class': 'ovr', 'penalty': 'l2'}
Best params RF: {'criterion': 'entropy', 'max_depth': 25, 'max_features': 'sqrt', 'n_estimators': 500}
Best params MLP: {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'constant', 'max_iter': 10000, 'solver': 'sgd'}



=== Embedding Model: LaBSE ===
KNN: 0.54
LogisticRegression: 0.56
SVM: 0.56
RandomForest: 0.58
MLP: 0.54

Best params KNN: {'algorithm': 'auto', 'n_neighbors': 15, 'p': 3, 'weights': 'uniform'}
Best params LR: {'C': 5, 'max_iter': 200000, 'solver': 'newton-cholesky'}
Best params SVM: {'C': 0.5, 'loss': 'squared_hinge', 'max_iter': 1000000, 'multi_class': 'ovr', 'penalty': 'l2'}
Best params RF: {'criterion': 'entropy', 'max_depth': 25, 'max_features': 'sqrt', 'n_estimators': 700}
Best params MLP: {'activation': 'tanh', 'alpha': 0.0001, 'early_stopping': True, 'hidden_layer_sizes': (128,), 'learning_rate': 'constant', 'max_iter': 10000, 'solver': 'adam'}




=== Embedding Model: intfloat/multilingual-e5-large ===
KNN: Accuracy = 0.49
LogisticRegression: Accuracy = 0.59
SVM: Accuracy = 0.61
RandomForest: Accuracy = 0.6
MLP: Accuracy = 0.62


=== Embedding Model: intfloat/multilingual-e5-large ===
KNN: 0.49
LogisticRegression: 0.62
SVM: 0.63
RandomForest: 0.58
MLP: 0.61

Best params KNN: {'algorithm': 'auto', 'n_neighbors': 20, 'p': 3, 'weights': 'distance'}
Best params LR: {'C': 10, 'max_iter': 200000, 'solver': 'newton-cholesky'}
Best params SVM: {'C': 1.5, 'loss': 'squared_hinge', 'max_iter': 1000000, 'multi_class': 'ovr', 'penalty': 'l2'}
Best params RF: {'criterion': 'gini', 'max_depth': 25, 'max_features': 'sqrt', 'n_estimators': 700}
Best params MLP: {'activation': 'tanh', 'alpha': 0.0001, 'early_stopping': True, 'hidden_layer_sizes': (128,), 'learning_rate': 'constant', 'max_iter': 10000, 'solver': 'adam'}



=== Embedding Model: intfloat/multilingual-e5-large ===
KNN: 0.53
LogisticRegression: 0.62
SVM: 0.63
RandomForest: 0.58
MLP: 0.6
Best params KNN: {'algorithm': 'ball_tree', 'n_neighbors': 35, 'p': 3, 'weights': 'distance'}
Best params LR: {'C': 11, 'max_iter': 200000, 'solver': 'newton-cholesky'}
Best params SVM: {'C': 1.4, 'loss': 'squared_hinge', 'max_iter': 10000000, 'multi_class': 'ovr', 'penalty': 'l2'}
Best params RF: {'criterion': 'gini', 'max_depth': 25, 'max_features': 'sqrt', 'n_estimators': 750}
Best params MLP: {'activation': 'tanh', 'alpha': 0.0001, 'early_stopping': True, 'hidden_layer_sizes': (256,), 'learning_rate': 'constant', 'max_iter': 10000, 'solver': 'adam'}



=== Embedding Model: intfloat/multilingual-e5-large ===

SVM: 0.62
Best params SVM: {'C': 19, 'decision_function_shape': 'ovo', 'gamma': 'auto', 'kernel': 'sigmoid', 'max_iter': -1, 'tol': 0.0001, 'verbose': False}

Micro precision average: 0.62
Macro precision average: 0.63 

Micro recall average: 0.62
Macro recall average: 0.62 

Micro f1 average: 0.62
Macro f1 average: 0.62 

Best model mean accuracy and std dev: 0.68 ± 0.04



SVM: 0.62
Best params SVM: {'C': 20, 'break_ties': True, 'decision_function_shape': 'ovr', 'gamma': 'auto', 'kernel': 'sigmoid', 'max_iter': -1, 'tol': 0.0001, 'verbose': False}

Micro precision average: 0.62
Macro precision average: 0.64 

Micro recall average: 0.62
Macro recall average: 0.62 

Micro f1 average: 0.62
Macro f1 average: 0.63 

Best model mean accuracy and std dev: 0.67 ± 0.03